import os
os.environ["CUDA_VISIBLE_DEVICES"] = "2"  # æŒ‡å®šä½¿ç”¨çš„ GPU ç¼–å·
import glob
import pandas as pd
import numpy as np
import nibabel as nib
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, Subset
from torchvision import transforms, models
from PIL import Image
from tqdm import tqdm  # ç”¨äºæ˜¾ç¤ºè¿›åº¦æ¡
import time

# ==========================================
# 1. é…ç½®å‚æ•°
# ==========================================
CSV_PATH = "./dataset/5_class_10_12_2025.csv"
DATA_ROOT = "./dataset/ADNI/ADNI"
IMG_SIZE = 224
BATCH_SIZE = 16          # å¦‚æœæ˜¾å­˜ä¸å¤Ÿï¼Œæ”¹å°è¿™ä¸ªæ•°å­— (ä¾‹å¦‚ 8 æˆ– 16)
LEARNING_RATE = 1e-4     # å­¦ä¹ ç‡
NUM_EPOCHS = 10          # è®­ç»ƒè½®æ•°
NUM_CLASSES = 5          # 5åˆ†ç±»

# æ ‡ç­¾æ˜ å°„
LABEL_MAP = {
    'CN': 0,
    'EMCI': 1,
    'LMCI': 2,
    'AD': 3,
    'MCI': 4
}

# è®¾å¤‡é…ç½®
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ğŸ”¥ ä½¿ç”¨è®¾å¤‡: {device}")

# ==========================================
# 2. è¾…åŠ©å‡½æ•° & Dataset å®šä¹‰
# ==========================================
def find_nii_path(root_dir, subject_id, image_id):
    """åœ¨ Subject æ–‡ä»¶å¤¹ä¸‹é€’å½’æŸ¥æ‰¾å…·ä½“çš„ NIfTI æ–‡ä»¶"""
    subject_dir = os.path.join(root_dir, subject_id)
    if not os.path.exists(subject_dir):
        return None
    patterns = [
        os.path.join(subject_dir, "**", f"*{image_id}*.nii"),
        os.path.join(subject_dir, "**", f"*{image_id}*.nii.gz")
    ]
    for pat in patterns:
        files = glob.glob(pat, recursive=True)
        if files:
            return files[0]
    return None

def extract_middle_slice(nii_path):
    """è¯»å– NIfTI å¹¶æå–å† çŠ¶é¢(Coronal)ä¸­é—´åˆ‡ç‰‡"""
    try:
        img = nib.load(nii_path)
        data = img.get_fdata()
        
        # å– Axis 1 (å† çŠ¶é¢) çš„ä¸­é—´ä¸€å¼ 
        slice_idx = data.shape[1] // 2
        slice_2d = data[:, slice_idx, :]
        
        # æ—‹è½¬æ ¡æ­£
        slice_2d = np.rot90(slice_2d)
        
        # !!! é‡è¦ï¼šç§»é™¤äº† plt.show() ä»¥å…é˜»æ–­è®­ç»ƒæµç¨‹ !!!
        
        # å½’ä¸€åŒ– (Min-Max) -> 0-255
        d_min, d_max = slice_2d.min(), slice_2d.max()
        if d_max - d_min > 0:
            slice_2d = (slice_2d - d_min) / (d_max - d_min)
        else:
            slice_2d = np.zeros_like(slice_2d)
            
        slice_2d = (slice_2d * 255).astype(np.uint8)
        return Image.fromarray(slice_2d)
        
    except Exception as e:
        print(f"Error reading {nii_path}: {e}")
        return None

class ADNI2DDataset(Dataset):
    def __init__(self, csv_file, root_dir, transform=None):
        self.transform = transform
        self.samples = []
        
        if not os.path.exists(csv_file):
            raise FileNotFoundError(f"CSV not found: {csv_file}")
            
        df = pd.read_csv(csv_file)
        # ä¸ºäº†ç¡®ä¿â€œæŒ‰é¡ºåºåˆ†â€æ˜¯æœ‰æ„ä¹‰çš„ï¼Œæˆ‘ä»¬é»˜è®¤ä¸åš shuffleï¼Œå®Œå…¨ä¾èµ– CSV çš„é¡ºåº
        
        print(f"ğŸš€ æ­£åœ¨æ‰«æè·¯å¾„ (CSVå…± {len(df)} æ¡)...")
        for _, row in df.iterrows():
            group = row['Group']
            if group not in LABEL_MAP:
                continue
            path = find_nii_path(root_dir, row['Subject'], row['Image Data ID'])
            if path:
                self.samples.append({
                    'path': path,
                    'label': LABEL_MAP[group]
                })
        print(f"âœ… æ•°æ®åŠ è½½å®Œæ¯•! æœ‰æ•ˆæ ·æœ¬æ•°: {len(self.samples)}")

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        item = self.samples[idx]
        img = extract_middle_slice(item['path'])
        
        if img is None:
            img = Image.new('L', (IMG_SIZE, IMG_SIZE)) # å¼‚å¸¸å¤„ç†ï¼šé»‘å›¾
            
        img = img.convert('RGB') # è½¬ä¸º RGB é€‚é… VGG
        
        if self.transform:
            img = self.transform(img)
            
        return img, item['label']

# ==========================================
# 3. å®šä¹‰ VGG16 æ¨¡å‹
# ==========================================
class VGG16ForAD(nn.Module):
    def __init__(self, num_classes=5):
        super(VGG16ForAD, self).__init__()
        # åŠ è½½é¢„è®­ç»ƒæƒé‡
        self.vgg16 = models.vgg16(weights=models.VGG16_Weights.DEFAULT)
        
        # ä¿®æ”¹åˆ†ç±»å±‚
        in_features = self.vgg16.classifier[6].in_features
        self.vgg16.classifier[6] = nn.Linear(in_features, num_classes)
        
    def forward(self, x):
        return self.vgg16(x)

# ==========================================
# 4. è®­ç»ƒä¸éªŒè¯å‡½æ•°
# ==========================================
def train_one_epoch(model, loader, criterion, optimizer):
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0
    
    # ä½¿ç”¨ tqdm æ˜¾ç¤ºè¿›åº¦æ¡
    loop = tqdm(loader, desc="Training", leave=False)
    
    for images, labels in loop:
        images, labels = images.to(device), labels.to(device)
        
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        
        loss.backward()
        optimizer.step()
        
        running_loss += loss.item()
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
        
        loop.set_postfix(loss=loss.item())
        
    epoch_loss = running_loss / len(loader)
    epoch_acc = 100 * correct / total
    return epoch_loss, epoch_acc

def evaluate(model, loader, criterion):
    model.eval()
    running_loss = 0.0
    correct = 0
    total = 0
    
    with torch.no_grad():
        for images, labels in loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)
            
            running_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
            
    loss = running_loss / len(loader)
    acc = 100 * correct / total
    return loss, acc

# ==========================================
# 5. ä¸»ç¨‹åº
# ==========================================
if __name__ == "__main__":
    # --- A. æ•°æ®å‡†å¤‡ ---
    print("\n[Step 1] å‡†å¤‡æ•°æ®...")
    data_transforms = transforms.Compose([
        transforms.Resize((IMG_SIZE, IMG_SIZE)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    full_dataset = ADNI2DDataset(CSV_PATH, DATA_ROOT, transform=data_transforms)
    
    # --- B. æŒ‰é¡ºåºåˆ‡åˆ†æ•°æ®é›† (7:1:2) ---
    total_len = len(full_dataset)
    train_len = int(total_len * 0.7)
    val_len = int(total_len * 0.1)
    test_len = total_len - train_len - val_len
    
    # ç”Ÿæˆæœ‰åºç´¢å¼•
    indices = list(range(total_len))
    train_idx = indices[:train_len]
    val_idx = indices[train_len : train_len + val_len]
    test_idx = indices[train_len + val_len :]
    
    print(f"ğŸ“Š æ•°æ®åˆ’åˆ† (Sequential Split):")
    print(f"   Train: {len(train_idx)} (0 - {train_len-1})")
    print(f"   Val:   {len(val_idx)} ({train_len} - {train_len+val_len-1})")
    print(f"   Test:  {len(test_idx)} ({train_len+val_len} - {total_len-1})")
    
    # ä½¿ç”¨ Subset åˆ›å»ºå­æ•°æ®é›†
    train_set = Subset(full_dataset, train_idx)
    val_set   = Subset(full_dataset, val_idx)
    test_set  = Subset(full_dataset, test_idx)
    
    # åˆ›å»º DataLoader
    train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True) # è®­ç»ƒå†…éƒ¨å¯ä»¥æ‰“ä¹±
    val_loader   = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False)
    test_loader  = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)
    
    # --- C. æ¨¡å‹åˆå§‹åŒ– ---
    print("\n[Step 2] åˆå§‹åŒ–æ¨¡å‹...")
    model = VGG16ForAD(num_classes=NUM_CLASSES)
    model = model.to(device)
    
    # å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)
    
    # --- D. å¼€å§‹è®­ç»ƒ ---
    print(f"\n[Step 3] å¼€å§‹è®­ç»ƒ ({NUM_EPOCHS} Epochs)...")
    start_time = time.time()
    
    for epoch in range(NUM_EPOCHS):
        # 1. è®­ç»ƒ
        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer)
        
        # 2. éªŒè¯
        val_loss, val_acc = evaluate(model, val_loader, criterion)
        
        print(f"Epoch [{epoch+1}/{NUM_EPOCHS}] "
              f"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | "
              f"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%")
              
    total_time = time.time() - start_time
    print(f"\nâœ¨ è®­ç»ƒå®Œæˆ! æ€»è€—æ—¶: {total_time:.0f}s")
    
    # --- E. æœ€ç»ˆæµ‹è¯• ---
    print("\n[Step 4] åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œæœ€ç»ˆè¯„ä¼°...")
    test_loss, test_acc = evaluate(model, test_loader, criterion)
    print(f"ğŸ† Test Set Accuracy: {test_acc:.2f}%")